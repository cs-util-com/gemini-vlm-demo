# Spatial Understanding Improvements

## Overview

This document describes the improvements made to the Gemini VLM Demo to enhance bounding box accuracy and add support for segmentation masks and points, based on the reference implementation from the Gemini team.

## Key Changes

### 1. API Configuration

**Model Selection:**
- Changed default model from `gemini-2.5-pro` to `gemini-2.5-flash`
- `gemini-2.5-flash` is specifically optimized for spatial understanding tasks

**Thinking Configuration:**
- Added `thinking_config: { thinking_budget: 0 }` (snake_case)
- Added `thinkingConfig: { thinkingBudget: 0 }` (camelCase fallback)
- Disabling thinking improves spatial understanding accuracy per Google's recommendations

**Temperature:**
- Added `temperature: 0.5` for consistent, reproducible results
- Balances creativity with deterministic output

### 2. Simplified Response Schema

**Before:** Complex nested schema with 140+ lines including:
- Multiple nested objects (image, detections, global_insights)
- Complex enums with 5+ values
- Multiple nullable fields with minItems/maxItems
- Deeply nested arrays (attributes, relationships, metrics)
- Format constraints and descriptions

**After:** Minimal schema with ~30 lines:
```json
{
  "type": "object",
  "properties": {
    "items": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "label": { "type": "string" },
          "category": { "type": "string" },
          "box_2d": { "type": "array", "items": { "type": "number" } },
          "mask": { "type": "string" },
          "points": { "type": "array", "items": { "type": "array", "items": { "type": "number" } } },
          "severity": { "type": "string" }
        },
        "required": ["label", "box_2d"]
      }
    }
  },
  "required": ["items"]
}
```

**Why this matters:**
- Avoids "too many states for serving" error
- Simpler schema = faster parsing and generation
- Follows Google's guidance on minimal schemas

### 3. Improved Prompt

**Before:** Long instructional prompt (~400 words) with:
- Detailed geometry explanations
- Multiple coordinate system instructions
- Complex category definitions
- Nested field explanations

**After:** Concise task-focused prompt (~80 words):
```
Detect objects and return a JSON object with items that each include a "label", 
"box_2d" in [y0, x0, y1, x1] normalized to 0-1000, an optional "mask" 
(base64-encoded PNG probability map), and an optional array of "points" with 
[y, x] pairs normalized to 0-1000.

Categorize findings across FOUR categories...
Limit to 25 items. Respond with JSON onlyâ€”no prose, no code fences.
```

**Key improvements:**
- Direct task description instead of system role
- Explicit output format requirements
- Item limit to prevent token overflow
- "No prose, no code fences" prevents wrapper text

### 4. Single-Call Multi-Feature Support

**New capability:** Request boxes, masks, and points in a single API call

**Response format:**
```json
{
  "items": [
    {
      "label": "ladder",
      "category": "object",
      "box_2d": [200, 100, 600, 500],
      "mask": "data:image/png;base64,iVBORw0KGgo...",
      "points": [[250, 150], [300, 200]]
    }
  ]
}
```

### 5. Visualization Enhancements

**Segmentation Masks:**
- Renders base64-encoded PNG masks as colored overlays
- 50% opacity for visibility
- Color-coded by detection category
- Properly scaled to bounding box dimensions

**Points:**
- Renders [y, x] coordinate pairs as circular markers
- 6px radius circles with white border
- Color-coded by category
- Properly handles normalized 0-1000 coordinates

**Implementation:**
- `drawMask()`: Loads mask image, applies category color, renders as overlay
- `drawPoints()`: Converts normalized coordinates to canvas pixels, draws circles

### 6. Response Format Conversion

**Problem:** New API format differs from existing codebase expectations

**Solution:** Conversion function maintains backward compatibility:
```javascript
function convertNewResponseToOldFormat(newResponse) {
  // Converts: {items: [...]} -> {detections: [...], global_insights: [...]}
  // Maps: box_2d -> bbox
  // Preserves: mask, points for visualization
  // Generates: missing IDs, default categories, confidence scores
}
```

## Testing

All existing tests pass:
- 122 tests across 5 test suites
- 97.7% statement coverage
- No breaking changes to public APIs

## Performance Characteristics

**Expected improvements:**
- Faster response times (flash model)
- More accurate bounding boxes (optimized model + simplified schema)
- Single API call instead of 3 separate calls (boxes, masks, points)
- Reduced token usage (simpler prompt and schema)

## Reference

Based on the official Google Gemini spatial understanding demo:
- Located in: `/referenceImplementations/genini-spatial-understanding-demo`
- Model: `gemini-2.5-flash`
- Thinking budget: 0 (disabled)
- Temperature: 0.5
- Downscale: 640px max dimension

## Migration Notes

**Backward Compatibility:**
- All existing visualization code continues to work
- UI interactions unchanged
- File upload/batch processing unchanged
- Export functionality unchanged

**New Features Available:**
- Masks automatically rendered when present in response
- Points automatically rendered when present in response
- No API changes needed for consuming code
